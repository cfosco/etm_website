<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Leveraging Temporal Context in Low Representational Power Regimes</title>
     <!-- Updated: Added Google Fonts -->
     <link rel="preconnect" href="https://fonts.googleapis.com">
     <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
     <link href="https://fonts.googleapis.com/css2?family=Merriweather:ital,wght@0,400;0,700;1,400;1,700&family=Open+Sans:wght@400;700&display=swap" rel="stylesheet">
     <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.0/css/all.min.css">
     <link rel="stylesheet" href="styles.css">
</head>



<body>
    <div class="content-container">

    <!-- Title card -->
    <section id="title-card">
        <h1>Leveraging Temporal Context in Low Representational Power Regimes</h1>
    <div class="authors">
        <a href="https://camilofosco.com" target="_blank">Camilo Fosco</a>,
        <a href="https://souyoungjin.github.io" target="_blank">Souyoung Jin</a>,
        <a href="https://www.emiliejosephs.com/" target="_blank">Emilie Josephs</a>,
        <a href="http://olivalab.mit.edu/audeoliva.html" target="_blank">Aude Oliva</a>
    </div>
    <p>
        <a href="https://www.mit.edu" target="_blank">MIT CSAIL</a>
    </p>
    <p>
        <a href="https://cvpr2023.example.com" target="_blank">CVPR 2023</a>
    </p>
    <div class="buttons">
        <a href="ETM_CVPR2023_cameraready_review.pdf" target="_blank">
            <i class="fas fa-star"></i> Paper
        </a>
        <a href="ETM_CVPR2023_cameraready_supplemental.pdf" target="_blank">
            <i class="fas fa-file-pdf"></i> Supplemental
        </a>
        <a href="https://github.com/cfosco/etm_project" target="_blank">
            <i class="fab fa-github"></i> Code
        </a>
    </div>
    <div style="display: flex; gap:2em;">
        <img src="imgs/modified_teaser1.png" alt="Events">
        <img src="imgs/modified_teaser2.png" alt="ETM">
    </div>
    </section>

    <div class="separator separator-1">
        <svg viewBox="0 0 100 10" preserveAspectRatio="none">
            <path d="M0,10 C50,0 50,10 100,10 V10 H0 Z"></path>
        </svg>
    </div>

    <!-- Abstract -->
    <section id="abstract">
        <h2>Abstract</h2>
        <p>Computer vision models are excellent at identifying and
            exploiting regularities in the world. However, it is com-
            putationally costly to learn these regularities from scratch.
            This presents a challenge for low-parameter models, like
            those running on edge devices (e.g. smartphones). Can
            the performance of models with low representational power
            be improved by supplementing training with additional in-
            formation about these statistical regularities? We explore
            this in the domains of action recognition and action antic-
            ipation, leveraging the fact that actions are typically em-
            bedded in stereotypical sequences. We introduce the Event
            Transition Matrix (ETM), computed from action labels in an
            untrimmed video dataset, which captures the temporal con-
            text of a given action, operationalized as the likelihood that
            it was preceded or followed by each other action in the set.
            We show that including information from the ETM during
            training improves action recognition and anticipation per-
            formance on various egocentric video datasets. Through
            ablation and control studies, we show that the coherent se-
            quence of information captured by our ETM is key to this
            effect, and we find that the benefit of this explicit represen-
            tation of temporal context is most pronounced for smaller
            models. </p>
        <img src="imgs/teaser_fig_v3.png" alt="Main results">
    </section>

    <!-- Method -->
    <section id="method">
    <h2>Proposed Approach</h2>
    <p>
      Our proposed approach has two main components: the Event Transition Matrix (ETM) and the pre-training using this matrix. The ETM is an efficient way to describe the temporal relation between events in videos. We leverage these relations to help recognize current events or predict past or future events given an input video snippet.
      We first create the ETM by computing the frequency with which each event comes before and after every other event, incorporating a decay function to account for temporal distance between events. Then, we normalize the matrix to obtain the row-wise and column-wise normalized matrices.
    </p>
    <p>
      For pre-training with the ETM, we use a model with three modules: one for predicting the present event, one for predicting past events, and one for predicting future events. We train the model to minimize the loss functions for these predictions, incorporating the ETM to capture the temporal context.
    </p>
    <img src="imgs/proposed_approach_2.png" alt="Overview of the proposed approach for pre-training with ETM" />
    <p>
    </p>
  </section>
  

    <!-- Results -->
    <section id="results">
        <h2>Results</h2>
        <p>
           We show that low-complexity models benefit more from the ETM protocol than larger models with more representational power. The figures below show performance comparisons, with and without ETM training, on several well-known model families.
        </p>
        <div style="display: flex;">
            <img src="imgs/perf_vs_flops_EK100_actionrec_movinet+x3d.png" alt="Result 1">
            <img src="imgs/perf_vs_flops_EK100_actionant_movinet+x3d.png" alt="Result 2">
        </div>

        <img src="imgs/qual_aa_2.png" alt="Qualitative examples for Action Anticipation">
    </section>

    </div>  

    <!-- Team -->
    <section id="team">
        <h2>Team</h2>
        <div class="authors">
        <div class="team-member">
            <img src="imgs/Camilo.png" alt="Camilo Fosco">
            <p>Camilo Fosco<br>
            camilolu [at] mit [dot] edu</p>
        </div>
        <div class="team-member">
            <img src="imgs/souyoung.png" alt="SouYoung Jin">
            <p>SouYoung Jin<br>
            souyoung [at] mit [dot] edu</p>
        </div>
        <div class="team-member">
            <img src="imgs/Emilie.webp" alt="Emilie Josephs">
            <p>Emilie Josephs<br>
            ejosephs [at] mit [dot] edu</p>
        </div>
        <div class="team-member">
            <img src="imgs/Aude.jpg" alt="Aude Oliva">
            <p>Aude Oliva <br>
            oliva [at] mit [dot] edu</p>
        </div>
    </div>
    </section>



    <!-- <script>
        document.addEventListener('DOMContentLoaded', () => {
            const titleCard = document.getElementById('title-card');
            const mouseOverlay = document.createElement('div');
            mouseOverlay.classList.add('mouse-overlay');
            document.body.appendChild(mouseOverlay);
        
            titleCard.addEventListener('mousemove', (event) => {
                mouseOverlay.style.display = 'block';
                mouseOverlay.style.top = event.clientY - mouseOverlay.offsetHeight / 2 + 'px';
                mouseOverlay.style.left = event.clientX - mouseOverlay.offsetWidth / 2 + 'px';
            });
        
            titleCard.addEventListener('mouseleave', () => {
                mouseOverlay.style.display = 'none';
            });
        });
    </script> -->
</body>
</html>
